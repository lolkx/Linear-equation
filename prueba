#packages

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input,Dense

#Ecuaci√≥n u(x,t)
    #du/dt+cdu/dx=0
    # u(x,0)=sen(x)

    # models

def seno(x):
    return tf.sin(x)

#tf.keras.utils.get_custom_objects()['seno'] = seno

def u0(x):
    return x**2

c=1

class multilayer_perceptron(tf.keras.Model):
    def train_step(self,data):
        x, t, sol = data
        #initial parameters
        t0=tf.constant([0.0], dtype=tf.float32)
        with tf.GradientTape() as tape:
            with tf.GradientTape() as tape2:
                tape2.watch(x)
                tape2.watch(t)
                tape2.watch(t0)
                uNN=self(x,t)
                uNN0=self(x,t0)
            uNN_dx=tape2.gradient(uNN,x)
            uNN_dt=tape2.gradient(uNN,t)
            u00=u0(x)
            loss=self.compiled_loss(uNN_dx,-c*uNN_dt)+self.compiled_loss(uNN0,u00)
        gradients=tape.gradient(loss,self.trainable_weights)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))
        self.compiled_metrics.update_state(sol, uNN)






#parametros redes
nInput=2
nOutput=1
nhiddenlayers=32
nnhiddenlayers=32
n_train=40

#hiperparametros
lr=0.001
epochs=100
batch_size=1


#parametros de entrenamiento
xmin=-500
xmax=500
tmin=0.001
tmax=100
x_train=np.linspace(xmin,xmax,n_train)
t_train=np.linspace(tmin,tmax,n_train)
u_train=np.zeros(n_train)
for i in range(0,n_train):
    u_train[i]=u0(x_train[i]-c*t_train[i])



#red

input=Input(shape=(nInput,))
y=Dense(nnhiddenlayers,activation='elu')(input)

for i in range(0,nhiddenlayers-1):
    y=Dense(nnhiddenlayers,activation='elu')(y)
    

output=Dense(1,activation=None)(y)
model=multilayer_perceptron(input,output)

# Metrica, perdida y optimizador

loss = tf.keras.losses.MeanSquaredError()
metrics = tf.keras.metrics.MeanSquaredError()
optimizer = tf.keras.optimizers.Adam(lr)

model.compile(loss=loss,optimizer=optimizer,metrics=[metrics])

#model.summary()
history=model.fit(x_train,t_train,u_train,batch_size=batch_size,epochs=epochs,verbose=1)




